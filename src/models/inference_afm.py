# src/models/inference_afm.py (æœ€çµ‚ç¢ºå®šç‰ˆ: 198Dãƒ¢ãƒ‡ãƒ«ã¨ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åˆã‚ã›ã¦ä¿®æ­£)

import torch
import torch.nn as nn
from pathlib import Path
import numpy as np
import pandas as pd
import random
import os
import torch.nn.functional as F


# ===================================================================
# 1. AFM MODEL DEFINITION (Z-Scoreå‡ºåŠ›ãƒ¢ãƒ‡ãƒ« - Clampã‚’å‰Šé™¤)
# ===================================================================

class AFM(nn.Module):
    def __init__(self, user_dim, movie_dim, edge_dim,
                 embedding_dim=32, # ğŸ’¥ ä¿®æ­£: K_EMBED=32
                 attn_size=32,     # ğŸ’¥ ä¿®æ­£: ATTN_SIZE=32
                 dropout_rate=0.2):
        super().__init__()

        self.user_embed = nn.Linear(user_dim, embedding_dim, bias=False)
        self.movie_embed = nn.Linear(movie_dim, embedding_dim, bias=False)

        attn_input_dim = embedding_dim + edge_dim
        self.attn_layer = nn.Sequential(
            nn.Linear(attn_input_dim, attn_size),
            nn.ReLU(),
            nn.Linear(attn_size, 1, bias=False)
        )
        self.dropout = nn.Dropout(dropout_rate)

        self.bias = nn.Parameter(torch.zeros(1))
        self.linear_u = nn.Linear(user_dim, 1, bias=False)
        self.linear_m = nn.Linear(movie_dim, 1, bias=False)

    def forward(self, u_feat, m_feat, e_attr):
        v_u = self.user_embed(u_feat)
        v_m = self.movie_embed(m_feat)

        interaction_term = v_u * v_m
        attn_input = torch.cat([interaction_term, e_attr], dim=-1)

        attn_score = self.attn_layer(attn_input)

        weighted_interaction = interaction_term * attn_score
        weighted_interaction = self.dropout(weighted_interaction)
        interaction_sum = torch.sum(weighted_interaction, dim=1)

        linear_term = self.bias + self.linear_u(u_feat).squeeze(1) + self.linear_m(m_feat).squeeze(1)

        prediction = linear_term + interaction_sum

        return prediction


# ===================================================================
# 2. å®šæ•°ãƒ»ãƒ‘ã‚¹è¨­å®š
# ===================================================================

PROJECT_ROOT = Path("/Users/watanabesaki/PycharmProjects/AFM")
DATA_PROCESSED = PROJECT_ROOT / "data/processed"
MODELS_DIR = PROJECT_ROOT / "models"
RESULTS_DIR = PROJECT_ROOT / "results"
RESULTS_DIR.mkdir(exist_ok=True)

# ğŸ’¥ Testãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚è©•ä¾¡ã‚’è¡Œã†ãŸã‚ã€VAL_PTã‚’TEST_PTã«ç½®ãæ›ãˆã¾ã™
TEST_PT = DATA_PROCESSED / "hetero_graph_test.pt"
MODEL_LOAD_PATH = MODELS_DIR / "afm_model.pt"
OUTPUT_CSV_PATH = RESULTS_DIR / "afm_inference_errors_test_set.csv" # ğŸ’¥ ãƒ•ã‚¡ã‚¤ãƒ«åå¤‰æ›´

# ğŸ’¥ ä¿®æ­£: æœ€çµ‚çš„ãªå­¦ç¿’æ™‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«åˆã‚ã›ã‚‹ (K_EMBED=32, ATTN_SIZE=32)
K_EMBED = 32
ATTN_SIZE = 32
DROPOUT_RATE = 0.2

# u_feat ã®çµ¶å¯¾ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
USER_MEAN_ABS_INDEX = 26
USER_STD_ABS_INDEX = 27
SLICED_USER_FEAT_DIM = 198 # Î¼ã¨Ïƒã‚’é™¤ã„ãŸæ¬¡å…ƒ


# ===================================================================
# 3. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ãƒ»ãƒ‡ãƒãƒ¼ãƒãƒ©ã‚¤ã‚ºãƒ­ã‚¸ãƒƒã‚¯ (198Då¯¾å¿œ)
# ===================================================================

def load_data_and_extract_info(path: Path):
    """ã‚°ãƒ©ãƒ•ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã€ãƒ‡ãƒãƒ¼ãƒãƒ©ã‚¤ã‚ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹ (198Då¯¾å¿œ)"""
    data = torch.load(path, weights_only=False)

    u_feat_all = data['user'].x # 200D
    m_feat_all = data['movie'].x

    edge_data = data['user', 'review', 'movie']

    u_indices, m_indices = edge_data.edge_index
    e_attr = edge_data.edge_attr
    y_norm = edge_data.y  # Z-Scoreã‚¿ãƒ¼ã‚²ãƒƒãƒˆ

    # 1. RawãªMean/Stdã‚’æŠ½å‡º (ãƒ‡ãƒãƒ¼ãƒãƒ©ã‚¤ã‚ºç”¨)
    user_mean_rating_all = u_feat_all[:, USER_MEAN_ABS_INDEX]
    user_std_rating_all = u_feat_all[:, USER_STD_ABS_INDEX]

    # æ¨™æº–åå·®ãŒ0ã®å ´åˆã®ã‚¼ãƒ­é™¤ç®—é˜²æ­¢ (1.0ã«ç½®æ›)
    user_std_rating_all = torch.where(user_std_rating_all == 0, torch.tensor(1.0, dtype=torch.float32), user_std_rating_all)

    # 2. ğŸ’¥ ç‰¹å¾´é‡ã‹ã‚‰ Mean/Std ã‚’å‰Šé™¤ (ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ç”¨: 200D -> 198D)
    features_before_mu = u_feat_all[:, :USER_MEAN_ABS_INDEX]         # 0 to 25
    features_after_sigma = u_feat_all[:, USER_STD_ABS_INDEX + 1:]   # 28 to 199
    u_feat_sliced_all = torch.cat([features_before_mu, features_after_sigma], dim=1) # 198D

    # 3. ã‚¨ãƒƒã‚¸ã®æ•°ã ã‘ç‰¹å¾´é‡ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¤‡è£½
    u_feat_indexed = u_feat_sliced_all[u_indices] # ğŸ’¥ 198D
    m_feat_indexed = m_feat_all[m_indices]

    # Raw Ratingã®çœŸã®å€¤ã®è¨ˆç®—: y_true_raw = (y_norm * u_std) + u_mean
    u_mean_indexed = user_mean_rating_all[u_indices]
    u_std_indexed = user_std_rating_all[u_indices]
    y_true_raw = (y_norm * u_std_indexed) + u_mean_indexed

    return u_feat_indexed, m_feat_indexed, e_attr, y_true_raw, u_indices, m_indices, u_mean_indexed, u_std_indexed


# ===================================================================
# 4. MAIN FUNCTION
# ===================================================================

def main():
    # æ¨è«–æ™‚ã‚‚ã‚·ãƒ¼ãƒ‰å›ºå®šã¯ç¶­æŒ
    random.seed(42)
    np.random.seed(42)
    torch.manual_seed(42)

    print("=" * 80)
    print("AFM MODEL INFERENCE AND EVALUATION (Test Set - Final Report)")
    print("=" * 80)

    # 1. ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ (TEST_PTã‚’ä½¿ç”¨)
    u_feat_indexed, m_feat_indexed, e_attr_indexed, y_true_raw, u_indices, m_indices, u_mean_indexed, u_std_indexed = load_data_and_extract_info(
        TEST_PT) # ğŸ’¥ TEST_PTã‚’ä½¿ç”¨

    user_dim = u_feat_indexed.shape[1]
    movie_dim = m_feat_indexed.shape[1]
    edge_dim = e_attr_indexed.shape[1]

    # 2. ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã¨é‡ã¿ãƒ­ãƒ¼ãƒ‰
    # user_dim=198 ã§ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
    model = AFM(user_dim, movie_dim, edge_dim, embedding_dim=K_EMBED, attn_size=ATTN_SIZE, dropout_rate=DROPOUT_RATE)

    try:
        model.load_state_dict(torch.load(MODEL_LOAD_PATH))
        print(f"[Model] Loaded best model weights from {MODEL_LOAD_PATH.name} (User Dim: {user_dim}D)")
    except Exception as e:
        print(f"[ERROR] Failed to load model weights. Please ensure the model was trained with 198D features. Error: {e}")
        return

    # -------------------------------------------------------------
    # ğŸ’¥ è¿½åŠ : ãƒ¬ãƒ“ãƒ¥ãƒ¼ç‰¹å¾´é‡ (e_attr) ã¨çœŸå€¤ (y_true_raw) ã®ç›¸é–¢åˆ†æ
    # -------------------------------------------------------------
    print("\n" + "=" * 80)
    print("ã€DEBUG: ãƒ¬ãƒ“ãƒ¥ãƒ¼ç‰¹å¾´é‡ (e_attr) ã®ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚¯æ¤œè¨¼ã€‘")

    # ãƒ†ãƒ³ã‚½ãƒ«ã‚’Numpyã«å¤‰æ›
    e_attr_np = e_attr_indexed.numpy()
    y_true_raw_np = y_true_raw.numpy()

    # ç›¸é–¢ã‚’è¨ˆç®— (å„ç‰¹å¾´é‡æ¬¡å…ƒ vs y_true_raw)
    correlations = []
    for i in range(e_attr_np.shape[1]):
        # e_attrã®ç‰¹å¾´é‡ãŒã™ã¹ã¦å®šæ•°ï¼ˆåˆ†æ•£ãŒ0ï¼‰ã®å ´åˆã€ç›¸é–¢è¨ˆç®—ã§NaNãŒå‡ºã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—
        if np.std(e_attr_np[:, i]) > 1e-6:
            corr = np.corrcoef(e_attr_np[:, i], y_true_raw_np)[0, 1]
        else:
            corr = 0.0  # å¤‰åŒ–ã—ãªã„ç‰¹å¾´é‡ã¯ãƒªãƒ¼ã‚¯ã®å¯èƒ½æ€§ãŒä½ã„
        correlations.append(corr)

    # çµ¶å¯¾å€¤ã®ç›¸é–¢ã§ã‚½ãƒ¼ãƒˆ
    abs_correlations = np.abs(correlations)
    sorted_indices = np.argsort(abs_correlations)[::-1]

    # ãƒˆãƒƒãƒ—5ã®ç›¸é–¢ã‚’å‡ºåŠ›
    print("-" * 80)
    print("Top 5 E_ATTR Features Correlated with Y_TRUE_RAW (Raw Rating):")
    for i in sorted_indices[:5]:
        print(f"  Dim {i:2d}: Correlation R = {correlations[i]:.6f}")

    print("-" * 80)
    print(f"ğŸ’¥ è­¦å‘Š: ã©ã®æ¬¡å…ƒã‚‚ç›¸é–¢ã®çµ¶å¯¾å€¤ãŒ 0.95 ã‚’è¶…ãˆã‚‹å ´åˆã€æ·±åˆ»ãªãƒªãƒ¼ã‚¯ãŒç–‘ã‚ã‚Œã¾ã™ã€‚")
    print("=" * 80)
    # -------------------------------------------------------------

    # 3. æ¨è«–ã¨ãƒ‡ãƒãƒ¼ãƒãƒ©ã‚¤ã‚º
    model.eval()
    with torch.no_grad():
        # ... (æ—¢å­˜ã®æ¨è«–ãƒ­ã‚¸ãƒƒã‚¯ã¯çœç•¥) ...
        y_pred_norm = model(u_feat_indexed, m_feat_indexed, e_attr_indexed)
        y_pred_raw = (y_pred_norm * u_std_indexed) + u_mean_indexed
        y_pred = torch.clamp(y_pred_raw, min=1.0, max=10.0)
        y_true_clamped = torch.clamp(y_true_raw, min=1.0, max=10.0)

        # RMSEã¨MAEã®è¨ˆç®— (Raw Ratingã‚¹ã‚±ãƒ¼ãƒ«)
        rmse = torch.sqrt(F.mse_loss(y_pred, y_true_clamped)).item()
        mae = F.l1_loss(y_pred, y_true_clamped).item()

        # ... (æ—¢å­˜ã®ãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºã¨CSVå‡ºåŠ›ã¯çœç•¥) ...
        print("-" * 30)
        print(f"[DEBUG] y_true_raw sample (clamped): {y_true_clamped[:5].numpy()}")
        print(f"[DEBUG] y_pred_raw sample (clamped): {y_pred[:5].numpy()}")
        print("-" * 30)
        print(f"[Accuracy Metrics] Final Test RMSE (Raw Rating): {rmse:.4f}")
        print(f"[Accuracy Metrics] Final Test MAE (Raw Rating): {mae:.4f}")
        print("-" * 30)

        # èª¤å·®ã®ä¸€è¦§ã‚’ä½œæˆ
        errors = (y_pred - y_true_clamped).numpy()
        results_df = pd.DataFrame({
            'user_idx': u_indices.numpy(),
            'movie_idx': m_indices.numpy(),
            'y_true_raw': y_true_clamped.numpy(),
            'y_pred': y_pred.numpy(),
            'error': errors
        })

    results_df.to_csv(OUTPUT_CSV_PATH, index=False)
    print(f"[Output] Error list saved to {OUTPUT_CSV_PATH}")


if __name__ == "__main__":
    main()